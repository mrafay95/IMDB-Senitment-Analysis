{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BeautifulSoup4 in /usr/local/lib/python3.8/site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /usr/local/lib/python3.8/site-packages (from BeautifulSoup4) (2.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/site-packages (from nltk) (2020.11.13)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp38-cp38-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 728 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (0.17.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-0.23.2 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install BeautifulSoup4\n",
    "!pip install nltk\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/muhammadrafay/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import the pandas package, then use the \"read_csv\" function to read\n",
    "# the labeled training data\n",
    "import pandas as pd       \n",
    "from bs4 import BeautifulSoup \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv(\"alldata.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"All in all, this is a movie for kids. We saw it tonight and my child loved it. At one point my kid's excitement was so great that sitting was impossible. However, I am a great fan of A.A. Milne's books which are very subtle and hide a wry intelligence behind the childlike quality of its leading characters. This film was not subtle. It seems a shame that Disney cannot see the benefit of making movies from more of the stories contained in those pages, although perhaps, it doesn't have the permission to use them. I found myself wishing the theater was replaying \\\"Winnie-the-Pooh and Tigger too\\\", instead. The characters voices were very good. I was only really bothered by Kanga. The music, however, was twice as loud in parts than the dialog, and incongruous to the film.<br /><br />As for the story, it was a bit preachy and militant in tone. Overall, I was disappointed, but I would go again just to see the same excitement on my child's face.<br /><br />I liked Lumpy's laugh....\"\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(train.iloc[2,3])\n",
    "print(train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning and Text Preprocessing\n",
    "\n",
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set movie reviews...\n",
      "\n",
      "Review 1000 of 50000\n",
      "\n",
      "Review 2000 of 50000\n",
      "\n",
      "Review 3000 of 50000\n",
      "\n",
      "Review 4000 of 50000\n",
      "\n",
      "Review 5000 of 50000\n",
      "\n",
      "Review 6000 of 50000\n",
      "\n",
      "Review 7000 of 50000\n",
      "\n",
      "Review 8000 of 50000\n",
      "\n",
      "Review 9000 of 50000\n",
      "\n",
      "Review 10000 of 50000\n",
      "\n",
      "Review 11000 of 50000\n",
      "\n",
      "Review 12000 of 50000\n",
      "\n",
      "Review 13000 of 50000\n",
      "\n",
      "Review 14000 of 50000\n",
      "\n",
      "Review 15000 of 50000\n",
      "\n",
      "Review 16000 of 50000\n",
      "\n",
      "Review 17000 of 50000\n",
      "\n",
      "Review 18000 of 50000\n",
      "\n",
      "Review 19000 of 50000\n",
      "\n",
      "Review 20000 of 50000\n",
      "\n",
      "Review 21000 of 50000\n",
      "\n",
      "Review 22000 of 50000\n",
      "\n",
      "Review 23000 of 50000\n",
      "\n",
      "Review 24000 of 50000\n",
      "\n",
      "Review 25000 of 50000\n",
      "\n",
      "Review 26000 of 50000\n",
      "\n",
      "Review 27000 of 50000\n",
      "\n",
      "Review 28000 of 50000\n",
      "\n",
      "Review 29000 of 50000\n",
      "\n",
      "Review 30000 of 50000\n",
      "\n",
      "Review 31000 of 50000\n",
      "\n",
      "Review 32000 of 50000\n",
      "\n",
      "Review 33000 of 50000\n",
      "\n",
      "Review 34000 of 50000\n",
      "\n",
      "Review 35000 of 50000\n",
      "\n",
      "Review 36000 of 50000\n",
      "\n",
      "Review 37000 of 50000\n",
      "\n",
      "Review 38000 of 50000\n",
      "\n",
      "Review 39000 of 50000\n",
      "\n",
      "Review 40000 of 50000\n",
      "\n",
      "Review 41000 of 50000\n",
      "\n",
      "Review 42000 of 50000\n",
      "\n",
      "Review 43000 of 50000\n",
      "\n",
      "Review 44000 of 50000\n",
      "\n",
      "Review 45000 of 50000\n",
      "\n",
      "Review 46000 of 50000\n",
      "\n",
      "Review 47000 of 50000\n",
      "\n",
      "Review 48000 of 50000\n",
      "\n",
      "Review 49000 of 50000\n",
      "\n",
      "Review 50000 of 50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_reviews = train.shape[0]\n",
    "\n",
    "print(\"Cleaning and parsing the training set movie reviews...\\n\")\n",
    "clean_train_reviews = []\n",
    "for i in range( 0, num_reviews ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        #print(\"Review %d of %d\\n\" % ( i+1, num_reviews ))                                                                   \n",
    "    clean_train_reviews.append( review_to_words( train.iloc[i,3] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating Features from a Bag of Words (Using scikit-learn)\n",
    "\n",
    "print(\"Creating the bag of words...\\n\")\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 2000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Bag of Words Vocabulary to my vocab.txt ...\n"
     ]
    }
   ],
   "source": [
    "# Saving Bag of Words Vocabulary to my vocab.txt ...\n",
    "\n",
    "print('Saving Bag of Words Vocabulary to my vocab.txt ...')\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "\n",
    "with open('myvocab.txt', 'w') as f:\n",
    "    for item in vectorizer.get_feature_names():\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
